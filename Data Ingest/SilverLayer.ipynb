{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "87393068-f630-46a2-9797-070b5a92cf78",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "### Silver Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bddce313-acad-410b-943d-039f1d40588f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "##### Descrição da estrutura do arquivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "098341c2-4b17-4433-add2-b5f647ea286f",
     "showTitle": true,
     "title": "Informação da"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivos encontrados no diretório dbfs:/covid/bronze/.\n",
      "Tipo de arquivo: Delta\n",
      "Tamanho total do arquivo: 19.15 MB\n",
      "Quantidade de linhas: 22712\n",
      "Quantidade de colunas: 737\n"
     ]
    }
   ],
   "source": [
    "# Caminho para o diretório da camada Bronze\n",
    "bronze_directory = \"dbfs:/covid/bronze/\" \n",
    "\n",
    "# Verificando se o diretório existe e contém arquivos\n",
    "try:\n",
    "    files = dbutils.fs.ls(bronze_directory)\n",
    "    if len(files) > 0:\n",
    "        print(f\"Arquivos encontrados no diretório {bronze_directory}.\")\n",
    "        \n",
    "        # Carregando os dados da camada Bronze\n",
    "        df_bronze = spark.read.format(\"delta\").load(bronze_directory)\n",
    "\n",
    "        # Quantidade de linhas e colunas\n",
    "        num_rows = df_bronze.count()\n",
    "        num_cols = len(df_bronze.columns)\n",
    "\n",
    "        # Tamanho do arquivo em MB\n",
    "        total_size_mb = sum([file.size for file in files]) / (1024 * 1024)\n",
    "\n",
    "        # Informações do dataset\n",
    "        print(f\"Tipo de arquivo: Delta\")\n",
    "        print(f\"Tamanho total do arquivo: {total_size_mb:.2f} MB\")\n",
    "        print(f\"Quantidade de linhas: {num_rows}\")\n",
    "        print(f\"Quantidade de colunas: {num_cols}\")\n",
    "    else:\n",
    "        print(f\"O diretório {bronze_directory} existe, mas está vazio.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao acessar ou processar o diretório {bronze_directory}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "effc3cf0-7bf4-4e94-a266-528cc7db3a89",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "##### Lendo e carregando a camada bronze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f6495ef5-96d4-4066-8744-65d471d8329b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados convertidos para o formato Delta na camada Silver.\n"
     ]
    }
   ],
   "source": [
    "# Definindo o diretório da camada Silver para armazenar em Delta\n",
    "silver_directory_delta = \"dbfs:/covid/silver/\"\n",
    "\n",
    "# Converter os dados para o formato Delta e salvar na camada Silver\n",
    "df_bronze.write.format(\"delta\").mode(\"overwrite\").save(silver_directory_delta)\n",
    "print(\"Dados convertidos para o formato Delta na camada Silver.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "521430d0-37be-4004-9da3-579c9327be64",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Caminho absoluto para o diretório da camada Bronze\n",
    "bronze_directory = \"dbfs:/covid/bronze/\"\n",
    "\n",
    "# Carregar os dados da camada Bronze\n",
    "df_silver = spark.read.format(\"delta\").load(bronze_directory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f2bf8da1-eafc-4ad5-a24c-9d8462487175",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "##### Calculando colunas com valores ausentes para remoção"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6bf808d4-556f-4a1a-ac6b-5c13c9817ecb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colunas removidas: []\n",
      "Total de colunas removidas: 0\n",
      "Total de colunas restantes: 27\n",
      "Total de registros restantes: 22712\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Contagem total de linhas antes da transformação\n",
    "total_rows = df_silver.count()\n",
    "\n",
    "# Calcular a contagem de valores não nulos em cada coluna\n",
    "non_null_counts = df_silver.select([F.count(F.when(F.col(c).isNotNull(), c)).alias(c) for c in df_silver.columns])\n",
    "\n",
    "# Coletar os resultados para calcular a proporção de nulos\n",
    "non_null_counts_dict = non_null_counts.collect()[0].asDict()\n",
    "\n",
    "# Identificar as colunas a serem removidas com mais de 20% de valores nulos\n",
    "cols_to_drop = [col for col, non_null_count in non_null_counts_dict.items() if (total_rows - non_null_count) / total_rows > 0.20]\n",
    "\n",
    "# Remover as colunas identificadas\n",
    "df_silver = df_silver.drop(*cols_to_drop)\n",
    "\n",
    "# Contagem das colunas e registros restantes\n",
    "num_cols_remaining = len(df_silver.columns)\n",
    "num_rows_remaining = df_silver.count()\n",
    "\n",
    "# Exibir informações\n",
    "num_cols_removed = len(cols_to_drop)\n",
    "print(f\"Colunas removidas: {cols_to_drop}\")\n",
    "print(f\"Total de colunas removidas: {num_cols_removed}\")\n",
    "print(f\"Total de colunas restantes: {num_cols_remaining}\")\n",
    "print(f\"Total de registros restantes: {num_rows_remaining}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fce62fe7-16d4-495c-8e3c-babc55100a08",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[17]: ['location_key',\n",
      " 'date',\n",
      " 'new_confirmed',\n",
      " 'new_deceased',\n",
      " 'cumulative_confirmed',\n",
      " 'cumulative_deceased',\n",
      " 'average_temperature_celsius',\n",
      " 'minimum_temperature_celsius',\n",
      " 'maximum_temperature_celsius',\n",
      " 'rainfall_mm',\n",
      " 'dew_point',\n",
      " 'relative_humidity',\n",
      " 'latitude',\n",
      " 'longitude',\n",
      " 'area_sq_km',\n",
      " 'place_id',\n",
      " 'wikidata_id',\n",
      " 'country_code',\n",
      " 'country_name',\n",
      " 'subregion1_code',\n",
      " 'subregion1_name',\n",
      " 'subregion2_code',\n",
      " 'subregion2_name',\n",
      " 'iso_3166_1_alpha_2',\n",
      " 'iso_3166_1_alpha_3',\n",
      " 'aggregation_level',\n",
      " 'population']"
     ]
    }
   ],
   "source": [
    "df_silver.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "be9f6113-c65f-4a72-b863-022d5042006d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- location_key: string (nullable = true)\n",
      " |-- date: date (nullable = true)\n",
      " |-- new_confirmed: integer (nullable = true)\n",
      " |-- new_deceased: integer (nullable = true)\n",
      " |-- cumulative_confirmed: integer (nullable = true)\n",
      " |-- cumulative_deceased: integer (nullable = true)\n",
      " |-- average_temperature_celsius: double (nullable = true)\n",
      " |-- minimum_temperature_celsius: double (nullable = true)\n",
      " |-- maximum_temperature_celsius: double (nullable = true)\n",
      " |-- rainfall_mm: double (nullable = true)\n",
      " |-- dew_point: double (nullable = true)\n",
      " |-- relative_humidity: double (nullable = true)\n",
      " |-- area_sq_km: integer (nullable = true)\n",
      " |-- country_name: string (nullable = true)\n",
      " |-- subregion1_name: string (nullable = true)\n",
      " |-- subregion2_name: string (nullable = true)\n",
      " |-- aggregation_level: integer (nullable = true)\n",
      " |-- population: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Selecionando apenas as colunas relevantes na camada Silver\n",
    "df_silver_selected = df_silver.select(\n",
    "    col('location_key'),\n",
    "    col('date'),\n",
    "    col('new_confirmed'),\n",
    "    col('new_deceased'),\n",
    "    col('cumulative_confirmed'),\n",
    "    col('cumulative_deceased'),\n",
    "    col('average_temperature_celsius'),\n",
    "    col('minimum_temperature_celsius'),\n",
    "    col('maximum_temperature_celsius'),\n",
    "    col('rainfall_mm'),\n",
    "    col('dew_point'),\n",
    "    col('relative_humidity'),\n",
    "    col('area_sq_km'),\n",
    "    col('country_name'),\n",
    "    col('subregion1_name'),\n",
    "    col('subregion2_name'),\n",
    "    col('aggregation_level'),\n",
    "    col('population')\n",
    ")\n",
    "\n",
    "# Exibir o esquema \n",
    "df_silver_selected.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "01b6f336-3f6b-4cbb-8e64-2fd3ba9997d5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "##### Transformações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b58232fa-6d7f-4f36-b8fc-1ef715c1f83f",
     "showTitle": false,
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+-------------+------------+--------------------+-------------------+---------------------------+---------------------------+---------------------------+-----------+---------+-----------------+----------+--------------------+---------------+---------------+-----------------+----------+\n",
      "|location_key|      date|new_confirmed|new_deceased|cumulative_confirmed|cumulative_deceased|average_temperature_celsius|minimum_temperature_celsius|maximum_temperature_celsius|rainfall_mm|dew_point|relative_humidity|area_sq_km|        country_name|subregion1_name|subregion2_name|aggregation_level|population|\n",
      "+------------+----------+-------------+------------+--------------------+-------------------+---------------------------+---------------------------+---------------------------+-----------+---------+-----------------+----------+--------------------+---------------+---------------+-----------------+----------+\n",
      "|          AE|2022-09-13|          402|           0|             1021191|               2342|                      34.64|                      28.67|                      41.88|        0.0|    22.39|            55.08|     83600|United Arab Emirates|           null|           null|                0|   9890400|\n",
      "|          AF|2022-09-13|          259|           0|              196663|               7791|                      -7.08|                     -15.39|                        1.0|        0.0|   -16.69|            49.02|    652860|         Afghanistan|           null|           null|                0|  38928341|\n",
      "|          AG|2022-09-14|           34|           0|                9008|                145|                      28.39|                       28.0|                       29.0|        0.0|    23.89|            76.64|       440| Antigua and Barbuda|           null|           null|                0|     97928|\n",
      "|          AO|2022-09-13|            0|           0|              103131|               1917|                      27.31|                       24.5|                       29.0|        0.0|     9.61|            33.08|   1246700|              Angola|           null|           null|                0|  32866267|\n",
      "|          AR|2022-09-13|            0|           0|             9697763|             129830|                       14.5|                       3.56|                      25.03|        0.0|     -2.1|            32.77|   2780400|           Argentina|           null|           null|                0|  44938712|\n",
      "+------------+----------+-------------+------------+--------------------+-------------------+---------------------------+---------------------------+---------------------------+-----------+---------+-----------------+----------+--------------------+---------------+---------------+-----------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import round\n",
    "\n",
    "# Arredondar as colunas climáticas e outras especificadas para duas casas decimais\n",
    "df_silver_transformed = df_silver_selected.withColumn('average_temperature_celsius', round(col('average_temperature_celsius'), 2)) \\\n",
    "    .withColumn('minimum_temperature_celsius', round(col('minimum_temperature_celsius'), 2)) \\\n",
    "    .withColumn('maximum_temperature_celsius', round(col('maximum_temperature_celsius'), 2)) \\\n",
    "    .withColumn('rainfall_mm', round(col('rainfall_mm'), 2)) \\\n",
    "    .withColumn('dew_point', round(col('dew_point'), 2)) \\\n",
    "    .withColumn('relative_humidity', round(col('relative_humidity'), 2))\n",
    "\n",
    "# Verificação dos primeiros registros após o arredondamento\n",
    "df_silver_transformed.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d9be7736-0c3a-4dd2-97c6-5835fb4ac78c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, round, to_date\n",
    "\n",
    "# Tratamento de valores nulos\n",
    "df_silver_cleaned = df_silver_transformed.fillna({\n",
    "    'new_confirmed': 0,\n",
    "    'new_deceased': 0,\n",
    "    'cumulative_confirmed': 0,\n",
    "    'cumulative_deceased': 0,\n",
    "    'average_temperature_celsius': df_silver_transformed.agg({'average_temperature_celsius': 'avg'}).first()[0],\n",
    "    'minimum_temperature_celsius': df_silver_transformed.agg({'minimum_temperature_celsius': 'avg'}).first()[0],\n",
    "    'maximum_temperature_celsius': df_silver_transformed.agg({'maximum_temperature_celsius': 'avg'}).first()[0],\n",
    "    'rainfall_mm': 0,\n",
    "    'dew_point': 0,\n",
    "    'relative_humidity': 0,\n",
    "    'population': 0\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a6610ad0-4def-4fd6-a0fe-b9bdc9f25f66",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Remover linhas onde colunas críticas como 'location_key' ou 'date' sejam nulas\n",
    "df_silver_cleaned = df_silver_cleaned.dropna(subset=['location_key', 'date'])\n",
    "\n",
    "# Verificação e remoção de duplicatas da coluna 'location_key'\n",
    "df_silver_cleaned = df_silver_cleaned.dropDuplicates(['location_key'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "60a633ad-420f-454c-a20c-daff2e40d172",
     "showTitle": false,
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+-------------+------------+--------------------+-------------------+---------------------------+---------------------------+---------------------------+-----------+---------+-----------------+----------+------------+---------------+--------------------+-----------------+----------+\n",
      "|location_key|      date|new_confirmed|new_deceased|cumulative_confirmed|cumulative_deceased|average_temperature_celsius|minimum_temperature_celsius|maximum_temperature_celsius|rainfall_mm|dew_point|relative_humidity|area_sq_km|country_name|subregion1_name|     subregion2_name|aggregation_level|population|\n",
      "+------------+----------+-------------+------------+--------------------+-------------------+---------------------------+---------------------------+---------------------------+-----------+---------+-----------------+----------+------------+---------------+--------------------+-----------------+----------+\n",
      "|       PT_18|2020-07-09|           11|           0|                 562|                 18|          21.52944278336474|         16.874698287578212|          26.63951028359071|        0.0|      0.0|              0.0|      null|    Portugal|       Alentejo|                null|                1|    705478|\n",
      "|MX_OAX_20236|2020-07-29|            0|           0|                   0|                  0|          21.52944278336474|         16.874698287578212|          26.63951028359071|        0.0|      0.0|              0.0|      null|      Mexico|         Oaxaca|San Marcial Ozolo...|                2|      1525|\n",
      "|       SD_NR|2020-10-11|            0|           0|                 438|                  0|          21.52944278336474|         16.874698287578212|          26.63951028359071|        0.0|      0.0|              0.0|    122123|       Sudan|     River Nile|                null|                1|   1472257|\n",
      "|       SD_DN|2020-10-11|            0|           0|                 146|                  0|          21.52944278336474|         16.874698287578212|          26.63951028359071|        0.0|      0.0|              0.0|    296420|       Sudan|   North Darfur|                null|                1|   1583179|\n",
      "|       SD_NB|2020-10-11|            0|           0|                  30|                  0|          21.52944278336474|         16.874698287578212|          26.63951028359071|        0.0|      0.0|              0.0|     45844|       Sudan|      Blue Nile|                null|                1|         0|\n",
      "|       SD_GD|2020-10-11|            0|           0|                 274|                  0|          21.52944278336474|         16.874698287578212|          26.63951028359071|        0.0|      0.0|              0.0|     75263|       Sudan|     Al Qadarif|                null|                1|         0|\n",
      "|       SD_KA|2020-10-11|            1|           0|                 228|                  0|          21.52944278336474|         16.874698287578212|          26.63951028359071|        0.0|      0.0|              0.0|     36710|       Sudan|        Kassala|                null|                1|         0|\n",
      "|       SD_SI|2020-10-11|            0|           0|                 243|                  0|          21.52944278336474|         16.874698287578212|          26.63951028359071|        0.0|      0.0|              0.0|     37844|       Sudan|         Sennar|                null|                1|         0|\n",
      "| CO_91_91669|2020-10-12|            0|           0|                   7|                  2|          21.52944278336474|         16.874698287578212|          26.63951028359071|        0.0|      0.0|              0.0|      null|    Colombia|       Amazonas|    Puerto Santander|                2|       565|\n",
      "|MX_OAX_20451|2020-11-14|            0|           0|                   0|                  0|          21.52944278336474|         16.874698287578212|          26.63951028359071|        0.0|      0.0|              0.0|      null|      Mexico|         Oaxaca|     Santiago Apoala|                2|      1053|\n",
      "+------------+----------+-------------+------------+--------------------+-------------------+---------------------------+---------------------------+---------------------------+-----------+---------+-----------------+----------+------------+---------------+--------------------+-----------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ordenando os dados pela coluna 'date'\n",
    "df_silver = df_silver_cleaned.orderBy(col('date'))\n",
    "\n",
    "# Verificação dos primeiros registros após o arredondamento e ordenação\n",
    "df_silver.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5b3e2ee3-ebfe-4f00-862a-806e5127f5c3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Aplicando testes de valores nulos, unicidade e intervalos de valores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "88e7dc5a-5938-43cc-83d6-da05d8e6c453",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teste passado: Coluna 'location_key' não contém valores nulos.\n",
      "Teste passado: Coluna 'location_key' é única.\n",
      "Teste passado: Coluna 'date' não contém valores nulos.\n",
      "Teste passado: Todos os valores na coluna 'average_temperature_celsius' estão dentro do intervalo [-100, 60].\n",
      "Out[33]: True"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.functions import col, count\n",
    "\n",
    "# Função para verificar se uma coluna não contém valores nulos\n",
    "def check_no_nulls(df: DataFrame, column_name: str) -> bool:\n",
    "    null_count = df.filter(col(column_name).isNull()).count()\n",
    "    assert null_count == 0, f\"Coluna '{column_name}' contém {null_count} valores nulos\"\n",
    "    print(f\"Teste passado: Coluna '{column_name}' não contém valores nulos.\")\n",
    "    return True\n",
    "\n",
    "# Função para verificar se uma coluna é única\n",
    "def check_uniqueness(df: DataFrame, column_name: str) -> bool:\n",
    "    unique_count = df.select(column_name).distinct().count()\n",
    "    total_count = df.count()\n",
    "    assert unique_count == total_count, f\"Coluna '{column_name}' contém valores duplicados.\"\n",
    "    print(f\"Teste passado: Coluna '{column_name}' é única.\")\n",
    "    return True\n",
    "\n",
    "# Função para verificar se os valores estão dentro de um intervalo\n",
    "def check_value_range(df: DataFrame, column_name: str, min_value: float, max_value: float) -> bool:\n",
    "    out_of_range_count = df.filter((col(column_name) < min_value) | (col(column_name) > max_value)).count()\n",
    "    assert out_of_range_count == 0, f\"Coluna '{column_name}' contém {out_of_range_count} valores fora do intervalo [{min_value}, {max_value}].\"\n",
    "    print(f\"Teste passado: Todos os valores na coluna '{column_name}' estão dentro do intervalo [{min_value}, {max_value}].\")\n",
    "    return True\n",
    "\n",
    "# Executando os testes de qualidade\n",
    "check_no_nulls(df_silver_transformed, 'location_key')\n",
    "check_uniqueness(df_silver_transformed, 'location_key')\n",
    "check_no_nulls(df_silver_transformed, 'date')\n",
    "check_value_range(df_silver_transformed, 'average_temperature_celsius', -100, 60)  # Exemplo de intervalo para temperatura\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "37858d40-5733-47bc-be19-df6f4bd05851",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados transformados salvos na camada Silver: /covid/silver/\n"
     ]
    }
   ],
   "source": [
    "# Caminho da camada Silver\n",
    "silver_directory = \"/covid/silver/\" \n",
    "\n",
    "# Escrever os dados transformados na camada Silver em formato Delta\n",
    "df_silver.write.format(\"delta\").mode(\"overwrite\").save(silver_directory)\n",
    "\n",
    "print(f\"Dados transformados salvos na camada Silver: {silver_directory}\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "SilverLayer",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
