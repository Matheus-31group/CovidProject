{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e3210a1d-ebe9-4cff-ad80-ef520f4f64f3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Estratégia de Monitoramento\n",
    "\n",
    "##### 01. Estratégia de Monitoramento para o Pipeline de ETL\n",
    "\n",
    "Abaixo, seguem algumas alternativas de estratégias de monitoramento:\n",
    "\n",
    "- **Monitoramento de Desempenho:**\n",
    "  - **Proposta:** Utilizar ferramentas nativas do Databricks, como Databricks Jobs e Metrics, para monitorar o desempenho das tarefas de ETL, incluindo tempo de execução, uso de recursos e outras métricas relevantes.\n",
    "  - **Justificativa:** A identificação de gargalos de desempenho permite ajustes e otimizações que garantem a eficiência e a estabilidade operacional do pipeline.\n",
    "\n",
    "- **Alertas e Notificações:**\n",
    "  - **Proposta:** Configurar alertas automáticos para situações críticas, como falhas no pipeline, atrasos na execução ou uso excessivo de recursos. Para isso, pode ser necessário configurar integrações.\n",
    "  - **Justificativa:** A implementação de um sistema de alertas proativo permite respostas rápidas a problemas, minimizando o impacto em processos críticos e aumentando a resiliência das operações.\n",
    "\n",
    "##### 02. Identificação de Métricas-Chave e Ferramentas de Monitoramento\n",
    "\n",
    "Abaixo, estão algumas métricas importantes e as respectivas ferramentas de monitoramento sugeridas:\n",
    "\n",
    "- **Métricas de Qualidade de Dados:**\n",
    "  - **Proposta:** Monitorar a integridade e a qualidade dos dados ao longo do pipeline, identificando inconsistências, valores faltantes ou anomalias.\n",
    "  - **Ferramentas:** \n",
    "    - Databricks Delta Lake para validação em tempo real\n",
    "    - Great Expectations para testes automatizados de qualidade de dados\n",
    "  - **Justificativa:** Garantir a confiabilidade dos dados carregados é essencial para a tomada de decisões baseadas em dados precisos e consistentes.\n",
    "\n",
    "- **Métricas de Carga de Trabalho:**\n",
    "  - **Proposta:** Acompanhar a utilização de recursos como CPU, memória e I/O durante a execução do pipeline.\n",
    "  - **Ferramentas:** \n",
    "    - Databricks Clusters Metrics\n",
    "    - Azure Monitor\n",
    "    - AWS CloudWatch\n",
    "  - **Justificativa:** A otimização na alocação de recursos evita custos desnecessários e assegura o desempenho desejado, adaptando o pipeline conforme as demandas de processamento.\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a06e1411-3407-4126-985b-66039c3403e6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Estratégias de Monitoramento",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
